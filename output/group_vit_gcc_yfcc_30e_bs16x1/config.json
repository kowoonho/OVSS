data:
  batch_size: 16
  pin_memory: true
  num_workers: 0
  shuffle_buffer: 10000
  seed: ${train.seed}
  dataset:
    meta:
      gcc3m:
        type: img_txt_pair
        path: /workspace/Dataset/local_data/gcc3m_shards
        prefix: gcc-train-{000000..000331}.tar
        length: 2891445
      gcc12m:
        type: img_txt_pair
        path: /workspace/Dataset/local_data/gcc12m_shards
        prefix: gcc-conceptual-12m-{000000..001242}.tar
        length: 11156203
      imagenet:
        type: img_cls_pair
        path: /workspace/Dataset/local_data/imagenet_shards
        prefix: imagenet-val-{000000..000009}.tar
        length: 50000
    train:
    - gcc3m
    val:
    - imagenet
  img_aug:
    deit_aug: true
    img_size: 224
    img_scale:
    - 0.08
    - 1.0
    interpolation: bilinear
    color_jitter: 0.4
    auto_augment: rand-m9-mstd0.5-inc1
    re_prob: 0.25
    re_mode: pixel
    re_count: 1
  text_aug:
    max_seq_len: 77
    multi_label: 3
    word_type: noun
train:
  start_epoch: 0
  epochs: 30
  warmup_epochs: 2
  base_lr: 6.25e-06
  weight_decay: 0.05
  warmup_lr: 1.5625e-08
  min_lr: 1.5625e-07
  clip_grad: 5.0
  accumulation_steps: 0
  amp_opt_level: O1
  seed: 0
  lr_scheduler:
    name: cosine
  optimizer:
    name: adamw
    eps: 1.0e-08
    betas:
    - 0.9
    - 0.999
evaluate:
  eval_only: false
  eval_freq: 1
  task:
  - cls
  - seg
  cls:
    save_best: true
    template: subset
  seg:
    save_best: true
    cfg: segmentation/configs/_base_/datasets/pascal_voc12.py
    template: simple
    opts: []
checkpoint:
  auto_resume: true
  resume: ''
  freq: 1
  max_kept: -1
  save_freq: 1
model_name: group_vit_gcc_yfcc_30e_bs16x1
output: output/group_vit_gcc_yfcc_30e_bs16x1
tag: default
print_freq: 10
seed: 0
wandb: true
local_rank: 0
vis: []
_base_: default.yml
model:
  type: MultiLabelContrastive
  img_encoder:
    type: GroupViT
    embed_dim: 384
    num_heads:
    - 6
    - 6
    - 6
    depths:
    - 6
    - 3
    - 3
    num_group_tokens:
    - 64
    - 8
    - 0
    num_output_groups:
    - 64
    - 8
    drop_rate: 0.0
    drop_path_rate: 0.1
  text_encoder:
    type: TextTransformer
    context_length: 77
    width: 256
    layers: 12
    vocab_size: 49408
  contrast_temperature: 0.07
  proj_num_layers: 2
  output_dim: 256
  multi_label: ${data.text_aug.multi_label}
